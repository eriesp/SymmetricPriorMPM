{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r3mx3aVB1Ueb","executionInfo":{"status":"ok","timestamp":1644828611368,"user_tz":-60,"elapsed":19980,"user":{"displayName":"Alessandro Sala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02185727170674564632"}},"outputId":"0d1bd4c9-8b9b-430f-b6f0-bfa283fd2be6"},"id":"r3mx3aVB1Ueb","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","source":["%cd /gdrive/My Drive/Bayes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XpxFC7331WWB","executionInfo":{"status":"ok","timestamp":1644828611369,"user_tz":-60,"elapsed":4,"user":{"displayName":"Alessandro Sala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02185727170674564632"}},"outputId":"88839433-f871-45b5-9a1d-e69692e3f0fd"},"id":"XpxFC7331WWB","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/gdrive/My Drive/Bayes\n"]}]},{"cell_type":"code","execution_count":null,"id":"7e08cfca","metadata":{"id":"7e08cfca"},"outputs":[],"source":["import numpy as np\n","from numpy.linalg import inv\n","from numpy.linalg import cholesky\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","import scipy as sp\n","\n","from tensorflow_probability.substrates import numpy as tfp\n","tfd = tfp.distributions"]},{"cell_type":"code","source":["def build_beta(beta_b, b, kd, p):\n","  beta = np.array(beta_b)\n","  beta = np.insert(beta, b-1, -np.sum([beta_b[i] for i in range(p-1)]))\n","  for i in range(kd):\n","    beta = np.insert(beta, int(p+i+(b-1)*kd), -np.sum([beta_b[(p-1)+j*kd+i] for j in range(p-1)]))\n","  return beta"],"metadata":{"id":"y_m_qLMQ6bsj"},"id":"y_m_qLMQ6bsj","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_beta_b(beta, b, kd, p):\n","  indices = [b-1]\n","  for i in range(p + (b-1)*kd, p + b*kd):\n","    indices.append(i)\n","  \n","  beta_b = np.delete(beta, indices)\n","  return beta_b"],"metadata":{"id":"p2xy5-Lw-0fY"},"id":"p2xy5-Lw-0fY","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"8f1705d4","metadata":{"id":"8f1705d4"},"outputs":[],"source":["def sample_fullcond_beta(X, Y, p, n, kd, W_tilda, b, sigma_b, alpha, A):\n","  indices = [b-1]\n","  for i in range(p + (b-1)*kd, p + b*kd):\n","    indices.append(i)\n","\n","  X_b = np.delete(X, indices, axis=1)\n","  X_b = np.delete(X_b, [i for i in range(b-1, p*n, p)], axis=0)\n","  W_b_tilda = np.delete(W_tilda, b-1, 0)\n","\n","  beta_hat_1 = np.dot(np.dot(np.transpose(X_b[0:(p-1),:]) , inv(sigma_b)) , X_b[0:(p-1),:])\n","  beta_hat_2 = np.dot(np.dot(np.transpose(X_b[0:(p-1),:]) , inv(sigma_b)) , W_b_tilda[:,0])\n","  for i in range(1,n-1):\n","    beta_hat_1 += np.dot(np.dot(np.transpose(X_b[i*(p-1):(i+1)*(p-1),:]) , inv(sigma_b)) , X_b[i*(p-1):(i+1)*(p-1),:])\n","    beta_hat_2 += np.dot(np.dot(np.transpose(X_b[i*(p-1):(i+1)*(p-1),:]) , inv(sigma_b)) , W_b_tilda[:,i])\n","\n","  beta_hat = np.dot(inv(beta_hat_1+inv(A)) , beta_hat_2)\n","  beta_tilda_b = np.random.multivariate_normal(beta_hat, (alpha**2) * inv(beta_hat_1+inv(A)))\n","\n","  return build_beta(beta_tilda_b, b, kd, p)   "]},{"cell_type":"code","source":["def eval_prob(X, nu_b, S_b, beta_tilda, W_tilda, n, b, p, kd):\n","  indices = [b-1]\n","  for i in range(p + (b-1)*kd, p + b*kd):\n","    indices.append(i)\n","\n","  W_tilda_b = np.delete(W_tilda, b-1, 0)\n","  X_b = np.delete(X, indices, axis=1)\n","  X_b = np.delete(X_b, [i for i in range(b-1, p*n, p)], axis=0)\n","\n","  beta_tilda_b = build_beta_b(beta_tilda, b, kd, p)\n","\n","  sum = np.outer(W_tilda_b[:,0] - np.dot(X_b[0:(p-1),:],beta_tilda_b) , W_tilda_b[:,0] - np.dot(X_b[0:(p-1),:],beta_tilda_b))\n","  for i in range(1,n-1):\n","    sum += np.outer(W_tilda_b[:,i] - np.dot(X_b[i*(p-1):(i+1)*(p-1),:],beta_tilda_b) , W_tilda_b[:,i] - np.dot(X_b[i*(p-1):(i+1)*(p-1),:],beta_tilda_b))\n","\n","  return (-0.5*(n+nu_b))*np.log(np.linalg.det(S_b + sum))"],"metadata":{"id":"AByXSno1tCc6"},"id":"AByXSno1tCc6","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sample_fullcond_b(X, nu_b, S_b, beta_tilda, W_tilda, n, b_old, p, kd):\n","  probs = []\n","  for i in range(p):\n","    probs.append(eval_prob(X, nu_b, S_b, beta_tilda, W_tilda, n, i+1, p, kd))\n","  probs = sp.special.softmax(probs)\n","\n","  b = np.argmax(np.random.multinomial(1, probs)) + 1\n","  print(b)\n","  return b"],"metadata":{"id":"OT_ObZnDoyQd"},"id":"OT_ObZnDoyQd","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"11a33fa3","metadata":{"id":"11a33fa3"},"outputs":[],"source":["def sample_fullcond_others(X, Y, nu_b, S_b, p, n, b, beta_tilda, W_tilda):\n","  b_old = b\n","  b = sample_fullcond_b(X, nu_b, S_b, beta_tilda, W_tilda, n, b_old, p, kd)\n","\n","  indices = [b-1]\n","  for i in range(p + (b-1)*kd, p + b*kd):\n","    indices.append(i)\n","\n","  X_b = np.delete(X, indices, axis=1)\n","  X_b = np.delete(X_b, [i for i in range(b-1, p*n, p)], axis=0)\n","  W_tilda_b = np.delete(W_tilda, b-1, 0)\n","  beta_tilda_b = build_beta_b(beta_tilda, int(b), kd, p)\n","\n","  sum = np.outer(W_tilda_b[:,0] - np.dot(X_b[0:(p-1),:],beta_tilda_b) , W_tilda_b[:,0] - np.dot(X_b[0:(p-1),:],beta_tilda_b))\n","  for i in range(1,n-1):\n","    sum += np.outer(W_tilda_b[:,i] - np.dot(X_b[i*(p-1):(i+1)*(p-1),:],beta_tilda_b) , W_tilda_b[:,i] - np.dot(X_b[i*(p-1):(i+1)*(p-1),:],beta_tilda_b))\n","\n","  sigma_tilda_b = np.array(sp.stats.invwishart.rvs(df=n+nu_b, scale=S_b+sum))\n","  alpha = np.sqrt(np.trace(sigma_tilda_b)/(p-1))\n","  sigma_b = sigma_tilda_b/alpha**2\n","  return alpha, sigma_b, b"]},{"cell_type":"code","execution_count":null,"id":"1196b814","metadata":{"id":"1196b814"},"outputs":[],"source":["def sample_fullcond_W(Y, X, p, n, kd, W_tilda, beta_tilda, b, sigma_b, alpha, r, m):\n","    ### following Albert and Chib strategy (1993) we can sample from a Normal for each Wij and then discard the draw if the conditions that we must impose\n","    ### are not satisfied; otherwise keep the result and store it\n","    indices = [b-1]\n","    for i in range(p + (b-1)*kd, p + b*kd):\n","      indices.append(i)\n","    \n","    X_b = np.delete(X, indices, axis=1)\n","    X_b = np.delete(X_b, [i for i in range(b-1, p*n, p)], axis=0)\n","    row_b = W_tilda[b-1,:]\n","    W_b_tilda = np.delete(W_tilda, b-1, 0)\n","    beta_b_tilda = build_beta_b(beta_tilda, b, kd, p)\n","\n","    sigma_tilda_b = alpha**2 * sigma_b\n","\n","    for i in range(n):\n","      for j in range(p-1):\n","        sigma_tilda_b_j = np.delete(np.delete(sigma_tilda_b, j, axis=0), j, axis=1) # matrix without row and colums j\n","        sig__jj = np.delete(sigma_tilda_b[:,j], j) # colum j without element j \n","        sig_j_j = np.delete(sigma_tilda_b[j,:], j) # row j without element j\n","        F = np.dot(inv(sigma_tilda_b_j),sig__jj)\n","        X_i = X_b[[k for k in range((p-1)*i, (p-1)*(i+1))],:]\n","        xij = X_i[j,:]\n","        X_i_j = np.delete(X_i, j, axis=0)\n","        W_i_j = np.delete(W_b_tilda[:,i], j)\n","        \n","        mean = np.dot(xij, beta_b_tilda) + np.dot(F, (W_i_j - np.dot(X_i_j, beta_b_tilda)))\n","        var = sigma_tilda_b[j,j] - np.dot(np.dot(sig_j_j,inv(sigma_tilda_b_j)),sig__jj)\n","        \n","        Yi = Y[i]-1\n","        proposal = np.random.normal(mean, var)\n","        \n","        if Yi == j and Yi != (b-1):\n","          if(proposal > -0.5*np.sum(W_i_j) and proposal > np.max(W_i_j)):\n","            W_b_tilda[j,i] = proposal\n","            r[0]+=1\n","          m[0]+=1\n","        \n","        if Yi != j and Yi != (b-1):\n","          if(proposal < W_tilda[Yi,i] and proposal > -np.sum(W_i_j) - W_tilda[Yi,i]):\n","            W_b_tilda[j,i] = proposal\n","            r[1]+=1\n","          m[1]+=1\n","        \n","        if Yi == (b-1):\n","          if(proposal < min(-0.5*np.sum(W_i_j), -1*(np.max(np.delete(W_b_tilda,j,axis=0)) + np.sum(W_i_j)))):\n","            W_b_tilda[j,i] = proposal\n","            r[2]+=1\n","          m[2]+=1\n","    \n","    W_tilda = np.insert(W_b_tilda, b-1, row_b, axis=0)\n","\n","    return W_tilda, r, m"]},{"cell_type":"code","execution_count":null,"id":"0fd11349","metadata":{"id":"0fd11349"},"outputs":[],"source":["def run_mcmc(X, Y, p, n, kd, ka, niter=6000, nburn=1000, thin=5):\n","    W = np.zeros(p)\n","    for i in range(n):\n","        W_i = np.random.multivariate_normal(np.zeros(p), np.eye(p))\n","        W_i[Y[i]-1], W_i[np.argmax(W_i)] = W_i[np.argmax(W_i)], W_i[Y[i]-1]\n","        W = np.column_stack((W,W_i))\n","    W = np.delete(W, 0, axis=1)\n","\n","    k = (p-1)*(kd+1)+ka\n","    A = sp.stats.invwishart.rvs(df=k+4, scale=(k+4)*np.eye(k))   # see McCulloch & Rossi\n","    # A = np.eye((p-1)*(kd+1)+ka)   # identity matrix\n","    b = int(np.random.randint(1,p+1,1))\n","    \n","    nu_b = p+1\n","    c = 1/(p-1)\n","    S_b = np.diag((1+c)*np.ones(p-1)) - c*np.ones((p-1,p-1))\n","    alpha = 1\n","    sigma_b = sp.stats.invwishart.rvs(df=nu_b, scale=S_b, size=1) ### pensare se fissare traccia a p-1\n","\n","    ### beta from a normal(0,A)\n","    beta_b = np.random.multivariate_normal(np.zeros((p-1)*(kd+1)+ka), A)\n","    beta = build_beta(beta_b, b, kd, p)\n","      \n","    W_tilda = alpha*W\n","    beta_tilda = alpha*beta\n","    out_W = np.empty([p,n])\n","    out_alpha = []\n","    out_beta = np.zeros([int((niter-nburn)/thin)-1,k+kd+ka])\n","    out_sigma = np.empty([p-1,p-1])\n","\n","    ### indeces to check the acceptance ratios in the sample of W\n","    r = [0,0,0]\n","    m = [0,0,0]\n","\n","    j = 0\n","\n","    for i in range(niter):\n","        if i % thin == 0:\n","            print(\"Iter: {0} / {1} \\n\".format(i+1, niter), flush=True)\n","\n","        W_tilda, r, m = sample_fullcond_W(Y, X, p, n, kd, W_tilda, beta_tilda, b, sigma_b, alpha, r, m)\n","        beta_tilda = sample_fullcond_beta(X, Y, p, n, kd, W_tilda, b, sigma_b, alpha, A)\n","        alpha, sigma, b = sample_fullcond_others(X, Y, nu_b, S_b, p, n, b, beta_tilda, W_tilda)\n","\n","        if(alpha > 100):\n","          print(\"ERROR: overflow encountered during computations\")\n","          break\n","   \n","        if i > nburn and i % thin == 0:\n","            out_W = np.concatenate((out_W,np.array(W_tilda/alpha)), axis=0)\n","            out_alpha.append(alpha)\n","            out_beta[j,:] = beta_tilda/alpha\n","            out_sigma = np.concatenate((out_sigma,np.array(sigma)), axis=0)\n","            j += 1\n","\n","    out_beta = out_beta[1:,:]\n","    print('acceptance ratios: ', r[0]/m[0], r[0], m[0])  \n","    print(r[1]/m[1], r[1], m[1])    \n","    print(r[2]/m[2], r[2], m[2])\n","    figs, axs = plt.subplots(k+1, 1, figsize=(14,140))\n","    axs[0].plot(out_alpha)\n","    for j in range(k):\n","      axs[j+1].plot(out_beta[:,j])\n","\n","    # use this only if you need to save the chains\n","    # out_beta = pd.DataFrame(out_beta)\n","    # out_beta.to_excel('out_beta.xlsx')  \n","    # out_alpha = pd.DataFrame(out_alpha)\n","    # out_alpha.to_excel('out_alpha.xlsx')\n","    # out_W = pd.DataFrame(out_W)\n","    # out_W.to_excel('out_W.xlsx')\n","    # out_W = np.array(out_W)\n","    # out_sigma = pd.DataFrame(out_sigma)\n","    # out_sigma.to_excel('out_sigma.xlsx')\n","\n","    out_W = out_W[p:,:]\n","    return out_W"]},{"cell_type":"code","source":["### MAIN ###\n","\n","# set the seed\n","np.random.seed(54)\n","\n","# load data\n","X = pd.read_csv('Your_dataset.csv')\n","\n","# impose right shape of data\n","X = np.array(X)\n","agents_indices = X[:,0]\n","X = np.delete(X, 0, axis=1)\n","\n","# define parameters\n","p = 10   # number of categories\n","n = 100   # number of agents\n","kd = 3   # agent specific covariates\n","ka = 1   # alternative specific covariates\n","niter = 1000\n","nburn = 100\n","thin = 5\n","\n","X = X[0:p*n,:]   # consider the first n agents\n","Y = X[[k for k in range(0,p*n, p)],-1].astype(int)\n","X = np.delete(X, -1, axis=1)\n","\n","# call run_mcmc\n","out = run_mcmc(X, Y, p, n, kd, ka, niter, nburn, thin)\n","\n","# extract category chosen by agents\n","utilities = np.zeros([p,n])\n","iter = out.shape[0]/p\n","util = np.zeros(n)\n","\n","for i in range(int(iter)):\n","  util = np.argmax(out[i*p:(i+1)*p,:],axis=0)\n","  for j in range(n):\n","    utilities[util[j],j] = utilities[util[j],j]+1\n","probabilities = utilities/iter\n","preferences = np.argmax(utilities,axis=0)+1\n","print(sum(preferences==Y))"],"metadata":{"id":"PEgfcnCR6FnR"},"id":"PEgfcnCR6FnR","execution_count":null,"outputs":[]},{"cell_type":"code","source":["### DIAGNOSTICS\n","import arviz as az\n","\n","beta = pd.read_excel('out_beta.xlsx', index_col=0)\n","beta = np.array(beta)\n","chains_az = az.convert_to_inference_data(\n","    {'beta1': beta[:,0],\n","     'beta2': beta[:,1],\n","     'beta3': beta[:,2],\n","     'beta4': beta[:,3],\n","     'beta5': beta[:,4],\n","     'beta6': beta[:,5],\n","     'beta7': beta[:,6],\n","     'beta8': beta[:,7],\n","     'beta9': beta[:,8],\n","     'beta10': beta[:,9],}\n",")\n","print(az.ess(chains_az))"],"metadata":{"id":"GYNm2WWle9m5"},"id":"GYNm2WWle9m5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["az.plot_autocorr(chains_az)\n","plt.show()"],"metadata":{"id":"sg8EYLcCfmWe"},"id":"sg8EYLcCfmWe","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"name":"sMNP(1).ipynb","provenance":[{"file_id":"1RH2_qDwB6Gf6r8fjXsqKyQO8cbbCrtx5","timestamp":1641833722939}],"collapsed_sections":[]},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":5}